# Conversational Emotion Recognition using Text and Audio Modalities
In this recent advancement, extraction and identification of human emotions plays a
crucial role in developing interpersonal relationship between human and machine.
Emotion recognition system are now been adopted in TV industries for training purposes
of the performers to improve their acting skills for connecting the audiences. Accordingly,
research is been carried out to study the effect of the emotional behaviour of human using
various modalities independently. In this research work, a MELD database is been used
which is a conversational-based repository originated from a ‘Friends’ TV series. Here,
two independent unimodal networks are implemented using the text and audio modalities
and their accuracy and performances are relatively compared for any differences.
Accordingly, for text unimodal a Bi-LSTM model is observed to be the efficient model
with an accuracy of 75% while a LSTM model is seen to be the superior model for audio
modality with its highest accuracy of 47%. 
